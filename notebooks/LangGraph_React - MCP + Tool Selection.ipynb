{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a basic ReAct Agent in LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set up API keys\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.11.5 environment at: /Users/sudhirpatil/code/oreilly-ai-agents/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m40 packages\u001b[0m \u001b[2min 553ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 64ms\u001b[0m\u001b[0m                                               \n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0mers==0.1.11                       \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-mcp-adapters\u001b[0m\u001b[2m==0.1.11\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!uv pip install google-search-results\n",
    "#!uv pip show google-search-results\n",
    "#!python --version\n",
    "# !uv pip show serpapi\n",
    "# !uv pip install langchain-anthropic\n",
    "!uv pip install langchain-mcp-adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['APIKeyNotProvided', 'BAIDU_ENGINE', 'BING_ENGINE', 'Client', 'EBAY_ENGINE', 'GOOGLE_ENGINE', 'GOOGLE_SCHOLAR_ENGINE', 'GoogleSearch', 'HOME_DEPOT_ENGINE', 'HTTPClient', 'HTTPConnectionError', 'HTTPError', 'Pagination', 'SearchIDNotProvided', 'SerpApiClient', 'SerpApiClientException', 'SerpApiError', 'SerpResults', 'YAHOO_ENGINE', 'YANDEX_ENGINE', 'YOUTUBE_ENGINE', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', 'account', 'core', 'exceptions', 'google_search', 'http', 'json', 'locations', 'models', 'pagination', 'requests', 'search', 'search_archive', 'serp_api_client', 'serp_api_client_exception', 'textui']\n"
     ]
    }
   ],
   "source": [
    "import serpapi\n",
    "print(dir(serpapi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'serpapi.google_search.GoogleSearch'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from serpapi.serp_api_client import *\n",
    "from serpapi import GoogleSearch\n",
    "print(GoogleSearch)\n",
    "# serpapi = SerpAPIWrapper()\n",
    "# serpapi.run('Sinan Ozdemir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-47NGgZAvFz-",
    "outputId": "72f0e0c9-0fa5-45b2-fd88-f3c9f710afa5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# alternative way to get a tool from langchain\n",
    "\n",
    "from langchain_community.agent_toolkits.load_tools import load_tools\n",
    "tools = load_tools([\"serpapi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\'Sinan is an active lecturer focusing on large language models and a former lecturer of data science at the Johns Hopkins University. He is the author of multiple textbooks on data science and machine learning including \"Quick Start Guide to LLMs\". ...\\', \\'Sinan Ozdemir type: Author.\\', \\'Sinan Ozdemir entity_type: people.\\', \\'Sinan Ozdemir kgmid: /g/11hcjs9cr6.\\', \\'Specialized in areas including time management as well as mathematics and computer science logistics.\\', \\'Helping companies leverage AI technology to solve complex problems. Founder, author, and consultant specializing in AI, LLMs, and data science.\\', \\'Data Scientist + Author + Entrepreneur. Check out my new book on LLMs on Amazon (Top 10 in AI/NLP) - sinanuozdemir.\\', \\'Sinan Ozdemir is a mathematician, data scientist, NLP expert, lecturer, and accomplished author. He is currently applying my extensive knowledge and experience ...\\', \"A beginner\\'s guide to essential math and coding skills for data fluency and machine learning by Sinan Ozdemir\", \\'NLP + Gen AI Expert / LLM whisperer. AI Author. Founder @Aikylie (acquired). Contributor on @Forbes. Fellow @YCombinator. San Francisco, CA.\\', \\'Sinan Ozdemir is a Data Scientist, Entrepreneur, Teacher, and Author. He is the founder of LoopGenius, a company that helps people get their first 100 ...\\', \\'Sinan Ozdemir is a leading expert in Generative Artificial Intelligence and Machine Learning, with a successful track record as the founder of a venture-backed\\', \\'Sensational episode for you today with the illustrious A.I. author, educator and entrepreneur Sinan Ozdemir on how LLM benchmarks are lying ...\\']'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0].run('sinan ozdemir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# Choose the LLM that will drive the agent\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "agent_executor = create_react_agent(llm, tools, prompt='Today is May 30th, 2025')  # true as of 5/30/2025 ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(model: Union[str, langchain_core.runnables.base.Runnable[Union[langchain_core.prompt_values.PromptValue, str, collections.abc.Sequence[Union[langchain_core.messages.base.BaseMessage, list[str], tuple[str, str], str, dict[str, Any]]]], Union[langchain_core.messages.base.BaseMessage, str]], Callable[[~StateSchema, langgraph.runtime.Runtime[~ContextT]], langchain_core.language_models.chat_models.BaseChatModel], Callable[[~StateSchema, langgraph.runtime.Runtime[~ContextT]], Awaitable[langchain_core.language_models.chat_models.BaseChatModel]], Callable[[~StateSchema, langgraph.runtime.Runtime[~ContextT]], langchain_core.runnables.base.Runnable[Union[langchain_core.prompt_values.PromptValue, str, collections.abc.Sequence[Union[langchain_core.messages.base.BaseMessage, list[str], tuple[str, str], str, dict[str, Any]]]], langchain_core.messages.base.BaseMessage]], Callable[[~StateSchema, langgraph.runtime.Runtime[~ContextT]], Awaitable[langchain_core.runnables.base.Runnable[Union[langchain_core.prompt_values.PromptValue, str, collections.abc.Sequence[Union[langchain_core.messages.base.BaseMessage, list[str], tuple[str, str], str, dict[str, Any]]]], langchain_core.messages.base.BaseMessage]]]], tools: Union[Sequence[Union[langchain_core.tools.base.BaseTool, Callable, dict[str, Any]]], langgraph.prebuilt.tool_node.ToolNode], *, prompt: Union[langchain_core.messages.system.SystemMessage, str, Callable[[~StateSchema], Union[langchain_core.prompt_values.PromptValue, str, collections.abc.Sequence[Union[langchain_core.messages.base.BaseMessage, list[str], tuple[str, str], str, dict[str, Any]]]]], langchain_core.runnables.base.Runnable[~StateSchema, Union[langchain_core.prompt_values.PromptValue, str, collections.abc.Sequence[Union[langchain_core.messages.base.BaseMessage, list[str], tuple[str, str], str, dict[str, Any]]]]], NoneType] = None, response_format: Union[dict, type[pydantic.main.BaseModel], tuple[str, Union[dict, type[pydantic.main.BaseModel]]], NoneType] = None, pre_model_hook: Union[langchain_core.runnables.base.Runnable[-Input, +Output], Callable[[-Input], +Output], Callable[[-Input], collections.abc.Awaitable[+Output]], Callable[[collections.abc.Iterator[-Input]], collections.abc.Iterator[+Output]], Callable[[collections.abc.AsyncIterator[-Input]], collections.abc.AsyncIterator[+Output]], langchain_core.runnables.base._RunnableCallableSync[-Input, +Output], langchain_core.runnables.base._RunnableCallableAsync[-Input, +Output], langchain_core.runnables.base._RunnableCallableIterator[-Input, +Output], langchain_core.runnables.base._RunnableCallableAsyncIterator[-Input, +Output], collections.abc.Mapping[str, Any], langgraph._internal._runnable._RunnableWithWriter[-Input, +Output], langgraph._internal._runnable._RunnableWithStore[-Input, +Output], langgraph._internal._runnable._RunnableWithWriterStore[-Input, +Output], langgraph._internal._runnable._RunnableWithConfigWriter[-Input, +Output], langgraph._internal._runnable._RunnableWithConfigStore[-Input, +Output], langgraph._internal._runnable._RunnableWithConfigWriterStore[-Input, +Output], NoneType] = None, post_model_hook: Union[langchain_core.runnables.base.Runnable[-Input, +Output], Callable[[-Input], +Output], Callable[[-Input], collections.abc.Awaitable[+Output]], Callable[[collections.abc.Iterator[-Input]], collections.abc.Iterator[+Output]], Callable[[collections.abc.AsyncIterator[-Input]], collections.abc.AsyncIterator[+Output]], langchain_core.runnables.base._RunnableCallableSync[-Input, +Output], langchain_core.runnables.base._RunnableCallableAsync[-Input, +Output], langchain_core.runnables.base._RunnableCallableIterator[-Input, +Output], langchain_core.runnables.base._RunnableCallableAsyncIterator[-Input, +Output], collections.abc.Mapping[str, Any], langgraph._internal._runnable._RunnableWithWriter[-Input, +Output], langgraph._internal._runnable._RunnableWithStore[-Input, +Output], langgraph._internal._runnable._RunnableWithWriterStore[-Input, +Output], langgraph._internal._runnable._RunnableWithConfigWriter[-Input, +Output], langgraph._internal._runnable._RunnableWithConfigStore[-Input, +Output], langgraph._internal._runnable._RunnableWithConfigWriterStore[-Input, +Output], NoneType] = None, state_schema: Optional[Type[~StateSchema]] = None, context_schema: Optional[Type[Any]] = None, checkpointer: Union[NoneType, bool, langgraph.checkpoint.base.BaseCheckpointSaver] = None, store: Optional[langgraph.store.base.BaseStore] = None, interrupt_before: Optional[list[str]] = None, interrupt_after: Optional[list[str]] = None, debug: bool = False, version: Literal['v1', 'v2'] = 'v2', name: Optional[str] = None, **deprecated_kwargs: Any) -> langgraph.graph.state.CompiledStateGraph\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.signature(create_react_agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile the graph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(agent_executor.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn our ReAct Agent into a Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph, END\n",
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_react_agent_into_chat(agent_executor):\n",
    "    \n",
    "    class ConvoState(MessagesState):\n",
    "        # MessagesState already has messages in it\n",
    "        end: bool\n",
    "    \n",
    "    def get_user_input(state):\n",
    "        user_msg = input(\"\\nðŸ§‘ You: \")\n",
    "        if user_msg.strip().lower() == \"exit\":\n",
    "            return {'end': True}\n",
    "        return {\"messages\": HumanMessage(content=user_msg)}\n",
    "    \n",
    "    def run_agent(state):\n",
    "        response = agent_executor.invoke({\"messages\": state[\"messages\"]})\n",
    "        print(f\"\\nðŸ¤– Agent: {response['messages'][-1].content}\")\n",
    "        return {\"messages\": AIMessage(content=response['messages'][-1].content)}\n",
    "    \n",
    "    graph_builder = StateGraph(ConvoState)\n",
    "    graph_builder.add_node(\"get_user_input\", get_user_input)\n",
    "    graph_builder.add_node(\"run_agent\", run_agent)\n",
    "    \n",
    "    graph_builder.set_entry_point(\"get_user_input\")\n",
    "    graph_builder.add_conditional_edges(\n",
    "        \"get_user_input\", \n",
    "        lambda state: 'end' if state.get('end') else 'go',\n",
    "        {\n",
    "            'end': END,\n",
    "            'go': 'run_agent'\n",
    "        }\n",
    "    )\n",
    "    graph_builder.add_edge(\"run_agent\", \"get_user_input\")\n",
    "    \n",
    "    graph = graph_builder.compile()\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¬ Start chatting with the agent! Type 'exit' to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§‘ You:  who is sudhir patil\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– Agent: Sudhir Patil appears to be a name associated with multiple individuals in different fields. Here are a few notable references:\n",
      "\n",
      "1. **Film Producer**: Sudhir Patil is known for his work in the Indian film industry, associated with projects like \"Rangkarmi\" (2013), \"Well Done Aai\" (2025), and \"Sasarcha Panga Sauticha Inga\" (2010).\n",
      "\n",
      "2. **Academic/Researcher**: There are mentions of a Sudhir Patil who is a postdoctoral researcher at the University of Florida, with interests in adaptive control, nonlinear control, and deep learning.\n",
      "\n",
      "3. **Tourism Professional**: Another Sudhir Patil was recently inducted into the Hall of Fame for Facilitating Tourism at the Rajasthan Travel Mart in Jaipur.\n",
      "\n",
      "4. **Architectural Consultant**: There is also a mention of Sudhir Patil and Associates, which has been operational since 1995, providing architectural and liaison consultancy services.\n",
      "\n",
      "If you have a specific context in mind for Sudhir Patil, please provide more details!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§‘ You:  sudhir patil who worked in yahoo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– Agent: I wasn't able to find specific information about a Sudhir Patil who worked at Yahoo. However, if you have any additional context or if you're looking for specific details regarding his role or contributions at Yahoo, please let me know!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§‘ You:  sudhir patil who is residing in singapore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ¤– Agent: Sudhir Patil is a seasoned IT professional residing in Singapore. He has experience working at various organizations, including Yahoo, and holds an Engineer's Degree in computer science. He has also worked at DBS Bank and has past roles at Standard Chartered Bank and Citi, among others.\n",
      "\n",
      "If you need more specific details about his career or current role, please let me know!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§‘ You:  exit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='who is sudhir patil', additional_kwargs={}, response_metadata={}, id='a2792177-ac1b-4cb0-9c07-5796b333e944'),\n",
       "  AIMessage(content='Sudhir Patil appears to be a name associated with multiple individuals in different fields. Here are a few notable references:\\n\\n1. **Film Producer**: Sudhir Patil is known for his work in the Indian film industry, associated with projects like \"Rangkarmi\" (2013), \"Well Done Aai\" (2025), and \"Sasarcha Panga Sauticha Inga\" (2010).\\n\\n2. **Academic/Researcher**: There are mentions of a Sudhir Patil who is a postdoctoral researcher at the University of Florida, with interests in adaptive control, nonlinear control, and deep learning.\\n\\n3. **Tourism Professional**: Another Sudhir Patil was recently inducted into the Hall of Fame for Facilitating Tourism at the Rajasthan Travel Mart in Jaipur.\\n\\n4. **Architectural Consultant**: There is also a mention of Sudhir Patil and Associates, which has been operational since 1995, providing architectural and liaison consultancy services.\\n\\nIf you have a specific context in mind for Sudhir Patil, please provide more details!', additional_kwargs={}, response_metadata={}, id='09d682ed-41f2-4f8d-8c79-b0b922ad187c'),\n",
       "  HumanMessage(content='sudhir patil who worked in yahoo', additional_kwargs={}, response_metadata={}, id='93a495f0-2d77-4382-a94d-a9d9ec93ce48'),\n",
       "  AIMessage(content=\"I wasn't able to find specific information about a Sudhir Patil who worked at Yahoo. However, if you have any additional context or if you're looking for specific details regarding his role or contributions at Yahoo, please let me know!\", additional_kwargs={}, response_metadata={}, id='461c003b-331f-48d7-9235-1cf4a133e3db'),\n",
       "  HumanMessage(content='sudhir patil who is residing in singapore', additional_kwargs={}, response_metadata={}, id='9123d533-c0ee-4ada-a7ed-212a14f99675'),\n",
       "  AIMessage(content=\"Sudhir Patil is a seasoned IT professional residing in Singapore. He has experience working at various organizations, including Yahoo, and holds an Engineer's Degree in computer science. He has also worked at DBS Bank and has past roles at Standard Chartered Bank and Citi, among others.\\n\\nIf you need more specific details about his career or current role, please let me know!\", additional_kwargs={}, response_metadata={}, id='756ac988-fedd-424d-bd48-86959c31d7ca')],\n",
       " 'end': True}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = turn_react_agent_into_chat(agent_executor)\n",
    "print(\"ðŸ’¬ Start chatting with the agent! Type 'exit' to stop.\")\n",
    "graph.invoke({\"messages\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compile the graph\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bringing MCP into the mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply nest_asyncio to handle nested event loops\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /Users/sudhirpatil/code/oreilly-ai-agents/notebooks/mcp_server.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Note this is NOT an production ready MCP server, don't include env variables this way. \n",
    "#  I'm doing this so I can work in a notebook\n",
    "MCP_SERVER = f'''\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "import os\n",
    "\n",
    "mcp = FastMCP(\"MCP Example\")\n",
    "\n",
    "@mcp.tool()\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@mcp.tool()\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@mcp.tool()\n",
    "def google_something(query: str) -> str:\n",
    "    \"\"\"Online Realtime Web Search\"\"\"\n",
    "    serpapi = SerpAPIWrapper(serpapi_api_key=\"{os.getenv(\"SERPAPI_API_KEY\")}\")\n",
    "    return serpapi.run(query)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"stdio\")\n",
    "'''\n",
    "\n",
    "mcp_path = 'mcp_server.py'\n",
    "\n",
    "with open(mcp_path, 'w') as f:\n",
    "    f.write(MCP_SERVER)\n",
    "\n",
    "print(\"Saved to:\", os.path.abspath(mcp_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Name: add\n",
      "Tool Description: Add two numbers\n",
      "Tool Args Schema: {'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b'], 'title': 'addArguments', 'type': 'object'}\n",
      "Tool Args : content_and_artifact\n",
      "------\n",
      "Tool Name: multiply\n",
      "Tool Description: Multiply two numbers\n",
      "Tool Args Schema: {'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b'], 'title': 'multiplyArguments', 'type': 'object'}\n",
      "Tool Args : content_and_artifact\n",
      "------\n",
      "Tool Name: google_something\n",
      "Tool Description: Online Realtime Web Search\n",
      "Tool Args Schema: {'properties': {'query': {'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'google_somethingArguments', 'type': 'object'}\n",
      "Tool Args : content_and_artifact\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"python\",\n",
    "    args=[os.path.abspath(mcp_path)]\n",
    ")\n",
    "\n",
    "async def agent_run_async(m):\n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            await session.initialize()\n",
    "            mcp_tools = await load_mcp_tools(session)\n",
    "            for tool in mcp_tools:\n",
    "                print(f'Tool Name: {tool.name}')\n",
    "                print(f'Tool Description: {tool.description}')\n",
    "                print(f'Tool Args Schema: {tool.args_schema}')\n",
    "                print(f'Tool Args : {tool.response_format}')\n",
    "                print('------')\n",
    "            agent = create_react_agent(llm, mcp_tools)\n",
    "            response = await agent.ainvoke({\"messages\": m})\n",
    "            return response\n",
    "\n",
    "agent_response = await agent_run_async(\"what's the current price of bitcoin times 12?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The current price of Bitcoin multiplied by 12 is $1,339,044.00.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 157, 'total_tokens': 177, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CPmUvc39XfsXhW69Rab9m4hf2Z9Ul', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--dc3be998-651c-436e-8710-4b37d14684fa-0', usage_metadata={'input_tokens': 157, 'output_tokens': 20, 'total_tokens': 177, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_response['messages'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.human.HumanMessage'> what's the current price of bitcoin times 12? \n",
      "----\n",
      "<class 'langchain_core.messages.ai.AIMessage'>  \n",
      "Tool Call: ID(call_CSQGHv72BwjRScC9AGxklj6I), Name(google_something), Args({\"query\":\"current price of Bitcoin\"})\n",
      "----\n",
      "<class 'langchain_core.messages.tool.ToolMessage'> 111,587.00 Tool ID:call_CSQGHv72BwjRScC9AGxklj6I\n",
      "----\n",
      "<class 'langchain_core.messages.ai.AIMessage'>  \n",
      "Tool Call: ID(call_qgkmQLdlvQpN5zDzJZcw6McR), Name(multiply), Args({\"a\":111587,\"b\":12})\n",
      "----\n",
      "<class 'langchain_core.messages.tool.ToolMessage'> 1339044 Tool ID:call_qgkmQLdlvQpN5zDzJZcw6McR\n",
      "----\n",
      "<class 'langchain_core.messages.ai.AIMessage'> The current price of Bitcoin multiplied by 12 is $1,339,044.00. \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for message in agent_response['messages']:\n",
    "    print(type(message), message.content, 'Tool ID:' + message.tool_call_id if hasattr(message, 'tool_call_id') else '')\n",
    "    if message.additional_kwargs.get('tool_calls'):\n",
    "        for tool_call in message.additional_kwargs.get('tool_calls'):\n",
    "            print(f'Tool Call: ID({tool_call[\"id\"]}), Name({tool_call[\"function\"][\"name\"]}), Args({tool_call[\"function\"][\"arguments\"]})')\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(agent_response['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for Accuracy + Positional Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_selection_test_data = [\n",
    "    ('What is the price of ethereum right now?', 'crypto_and_nft_tool'),\n",
    "    ('What is the price of bitcoin right now?', 'crypto_and_nft_tool'),\n",
    "    ('Check the floor price of the world of women nft', 'crypto_and_nft_tool'),\n",
    "\n",
    "    ('Add a new row and just write \"To do\" in it', 'google_spreadsheet_tool'),\n",
    "    ('Add this data to the spreadsheet: \"1, 2, 3\"', 'google_spreadsheet_tool'),\n",
    "    ('Add: \"Sinan, LoopGenius\" to the spreadsheet', 'google_spreadsheet_tool'),\n",
    "\n",
    "    ('Go to https://loopgenius.com and tell me about it', 'firecrawl_tool'),\n",
    "    ('Visit https://github.com/trending and list top repositories', 'firecrawl_tool'),\n",
    "    ('Scrape the main headlines from https://news.ycombinator.com', 'firecrawl_tool'),\n",
    "    ('Go to https://en.wikipedia.org/wiki/Python_(programming_language) and summarize the introduction', 'firecrawl_tool'),\n",
    "    ('Check the documentation at https://pytorch.org and tell me the latest version name', 'firecrawl_tool'),\n",
    "    ('Visit https://openai.com and summarize the homepage', 'firecrawl_tool'),\n",
    "    ('What is the headline on https://bbc.com/news', 'firecrawl_tool'),\n",
    "\n",
    "    ('What are the current gas prices in Chicago?', 'serp_tool'),\n",
    "    ('What is the weather in San Francisco?', 'serp_tool'),\n",
    "    ('Find the intro.co link for Sinan Ozdemir', 'serp_tool'),\n",
    "    ('What is the release date of the next Marvel movie?', 'serp_tool'),\n",
    "    ('Who won the latest Super Bowl?', 'serp_tool'),\n",
    "    ('What are the top restaurants in New York City?', 'serp_tool'),\n",
    "    ('Get the latest stock price for Apple (AAPL)', 'serp_tool'),\n",
    "    ('List the top 5 popular programming languages in 2024', 'serp_tool'),\n",
    "    ('Look up the conversion from 98 degrees Fahrenheit to Celsius on the web', 'serp_tool'),\n",
    "\n",
    "    ('Convert 98 degrees Fahrenheit to Celsius using Python', 'python_repl_tool'),\n",
    "    ('Write a function that yields the nth fibonacci number and use it to find the 100th fibonacci number', 'python_repl_tool'),\n",
    "    ('Calculate the factorial of 10 using Python', 'python_repl_tool'),\n",
    "    ('Calculate 15% of 34543.453', 'python_repl_tool'),\n",
    "    ('Convert 42 kilometers to miles using a function in Python', 'python_repl_tool'),\n",
    "    ('Generate a random number between 1 and 1000', 'python_repl_tool'),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: /Users/sudhirpatil/code/oreilly-ai-agents/notebooks/random_mcp_server.py\n",
      "Tool order: ['google_spreadsheet_tool', 'crypto_and_nft_tool', 'python_repl_tool', 'serp_tool', 'firecrawl_tool']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# Define tool snippets\n",
    "tool_snippets = [\n",
    "    '''\n",
    "@mcp.tool()\n",
    "def google_spreadsheet_tool(action: str = \"append_to_sheet\", **kwargs) -> dict:\n",
    "    \"\"\"\n",
    "    Executes specified actions on the Google Spreadsheet.\n",
    "\n",
    "    :param action: The action to perform (\"append_to_sheet\", \"search\", \"insert_into_cell\", \"get_data_in_range\", \"describe\").\n",
    "    :Additional arguments for each specific action:\n",
    "        - \"search\": \n",
    "            \"search\" will return the row indices where the search_value is found in the column_name.\n",
    "            Requires 'search_value' and 'column_name'. Example: {\"action\": \"search\", \"search_value\": \"John\", \"column_name\": \"Name\"}\n",
    "        - \"append_to_sheet\":\n",
    "            \"append_to_sheet\" will append the data to the end of the sheet.\n",
    "            Requires 'data'. Example: {\"action\": \"append_to_sheet\", \"data\": [[\"John\", \"Doe\", \"john.doe@example.com\"], [\"Jane\", \"Smith\", \"jane.smith@example.com\"]]}\n",
    "        - \"insert_into_cell\": \n",
    "            \"insert_into_cell\" will insert the value into the specified cell.\n",
    "            Requires 'value' and 'cell'. Example: {\"action\": \"insert_into_cell\", \"value\": \"New Value\", \"cell\": \"A1\"}\n",
    "        - \"get_data_in_range\": \n",
    "            \"get_data_in_range\" will return the data in the specified range.\n",
    "            Requires 'range_name'. Example: {\"action\": \"get_data_in_range\", \"range_name\": \"Sheet1!A1:B2\"} or {\"action\": \"get_data_in_range\",    \"range_name\": \"Contacts!A12:G28\"}\n",
    "        - \"describe\": \n",
    "            \"describe\" will return the number of columns and rows in the sheet.\n",
    "            No additional arguments. Example: {\"action\": \"describe\"}\n",
    "    :return: The result of the operation.\n",
    "    \"\"\"\n",
    "''',\n",
    "    '''\n",
    "@mcp.tool()\n",
    "def crypto_and_nft_tool(query: str) -> str:\n",
    "    \"\"\"Get current cryptocurrency prices and NFT prices around the world and for a specific wallet.\"\"\"\n",
    "    return f\"Fake response for crypto/NFT query: {query}\"\n",
    "''',\n",
    "    '''\n",
    "@mcp.tool()\n",
    "def firecrawl_tool(website_url: str) -> str:\n",
    "    \"\"\"\n",
    "    Crawl webpages and return a markdown version of the html on the page\n",
    "    :param website_url: The URL of the website to scrape\n",
    "    \"\"\"\n",
    "    return f\"Scraped data from: {website_url}\"\n",
    "''',\n",
    "    '''\n",
    "@mcp.tool()\n",
    "def serp_tool(query: str) -> str:\n",
    "    \"\"\"Search the web for information using the Google Search Engine\"\"\"\n",
    "    return f\"Search result for query: {query}\"\n",
    "''',\n",
    "    '''\n",
    "@mcp.tool()\n",
    "def python_repl_tool(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Execute valid python code and returns the printed values in the code\n",
    "    :param command: The Python command to run. Always end with a print statement to show the output like \"print(output)\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = eval(code)\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "'''\n",
    "]\n",
    "\n",
    "def generate_random_mcp_order(mcp_path='random_mcp_server.py'):\n",
    "    # Shuffle tool definitions\n",
    "    random.shuffle(tool_snippets)\n",
    "    \n",
    "    # Create full server code\n",
    "    MCP_SERVER = f'''\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "mcp = FastMCP(\"MCP Example\")\n",
    "{''.join(tool_snippets)}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"stdio\")\n",
    "    '''\n",
    "    \n",
    "    # Save to file\n",
    "    with open(mcp_path, 'w') as f:\n",
    "        f.write(MCP_SERVER)\n",
    "    \n",
    "    return os.path.abspath(mcp_path), [t.split('def')[-1].split('(')[0].strip() for t in tool_snippets]\n",
    "random_mcp, tools = generate_random_mcp_order()\n",
    "\n",
    "print(f\"Saved to: {random_mcp}\\nTool order: {tools}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['google_spreadsheet_tool',\n",
       " 'crypto_and_nft_tool',\n",
       " 'python_repl_tool',\n",
       " 'serp_tool',\n",
       " 'firecrawl_tool']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages.human import HumanMessage\n",
    "\n",
    "async def tool_use_run(llm, initial_message):\n",
    "    random_mcp_path, mcp_tool_order = generate_random_mcp_order()\n",
    "    server_params = StdioServerParameters(command=\"python\", args=[random_mcp_path])\n",
    "    \n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            await session.initialize()\n",
    "            tools = await load_mcp_tools(session)\n",
    "            ai_message = llm.bind_tools(tools).invoke([HumanMessage(content=initial_message)])\n",
    "            tools_used = []\n",
    "            if type(ai_message.content) == list:\n",
    "                for c in ai_message.content:  # anthropic\n",
    "                    if c['type'] == 'tool_use':\n",
    "                        tools_used.append((c['name'], c['input']))\n",
    "            if hasattr(ai_message, 'additional_kwargs') and 'tool_calls' in ai_message.additional_kwargs:  # openai\n",
    "                for tc in ai_message.additional_kwargs['tool_calls']:\n",
    "                    tools_used.append((tc['function']['name'], tc['function']['arguments']))\n",
    "            return ai_message, tools_used, mcp_tool_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  + Exception Group Traceback (most recent call last):\n",
      "  |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3697, in run_code\n",
      "  |     await eval(code_obj, self.user_global_ns, self.user_ns)\n",
      "  |   File \"/var/folders/s6/2yjn7mrx2k1ch9m_rsw_dpj00000gn/T/ipykernel_33666/2256591507.py\", line 2, in <module>\n",
      "  |     await tool_use_run(llm, 'look up Sinan Ozdemir')\n",
      "  |   File \"/var/folders/s6/2yjn7mrx2k1ch9m_rsw_dpj00000gn/T/ipykernel_33666/1874888625.py\", line 7, in tool_use_run\n",
      "  |     async with stdio_client(server_params) as (read, write):\n",
      "  |   File \"/Users/sudhirpatil/miniconda3/lib/python3.11/contextlib.py\", line 222, in __aexit__\n",
      "  |     await self.gen.athrow(typ, value, traceback)\n",
      "  |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/mcp/client/stdio/__init__.py\", line 181, in stdio_client\n",
      "  |     async with (\n",
      "  |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 781, in __aexit__\n",
      "  |     raise BaseExceptionGroup(\n",
      "  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "  +-+---------------- 1 ----------------\n",
      "    | Exception Group Traceback (most recent call last):\n",
      "    |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/mcp/client/stdio/__init__.py\", line 188, in stdio_client\n",
      "    |     yield read_stream, write_stream\n",
      "    |   File \"/var/folders/s6/2yjn7mrx2k1ch9m_rsw_dpj00000gn/T/ipykernel_33666/1874888625.py\", line 8, in tool_use_run\n",
      "    |     async with ClientSession(read, write) as session:\n",
      "    |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 781, in __aexit__\n",
      "    |     raise BaseExceptionGroup(\n",
      "    | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "    +-+---------------- 1 ----------------\n",
      "      | Traceback (most recent call last):\n",
      "      |   File \"/var/folders/s6/2yjn7mrx2k1ch9m_rsw_dpj00000gn/T/ipykernel_33666/1874888625.py\", line 11, in tool_use_run\n",
      "      |     ai_message = llm.bind_tools(tools).invoke([HumanMessage(content=initial_message)])\n",
      "      |                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 5711, in invoke\n",
      "      |     return self.bound.invoke(\n",
      "      |            ^^^^^^^^^^^^^^^^^^\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 395, in invoke\n",
      "      |     self.generate_prompt(\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 1025, in generate_prompt\n",
      "      |     return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "      |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 842, in generate\n",
      "      |     self._generate_with_cache(\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 1091, in _generate_with_cache\n",
      "      |     result = self._generate(\n",
      "      |              ^^^^^^^^^^^^^^^\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/langchain_anthropic/chat_models.py\", line 1764, in _generate\n",
      "      |     data = self._create(payload)\n",
      "      |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/langchain_anthropic/chat_models.py\", line 1623, in _create\n",
      "      |     return self._client.messages.create(**payload)\n",
      "      |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/anthropic/_utils/_utils.py\", line 282, in wrapper\n",
      "      |     return func(*args, **kwargs)\n",
      "      |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/anthropic/resources/messages/messages.py\", line 930, in create\n",
      "      |     return self._post(\n",
      "      |            ^^^^^^^^^^^\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/anthropic/_base_client.py\", line 1324, in post\n",
      "      |     return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "      |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/anthropic/_base_client.py\", line 1033, in request\n",
      "      |     request = self._build_request(options, retries_taken=retries_taken)\n",
      "      |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/anthropic/_base_client.py\", line 506, in _build_request\n",
      "      |     headers = self._build_headers(options, retries_taken=retries_taken)\n",
      "      |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/anthropic/_base_client.py\", line 447, in _build_headers\n",
      "      |     self._validate_headers(headers_dict, custom_headers)\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/anthropic/_client.py\", line 196, in _validate_headers\n",
      "      |     raise TypeError(\n",
      "      | TypeError: \"Could not resolve authentication method. Expected either api_key or auth_token to be set. Or for one of the `X-Api-Key` or `Authorization` headers to be explicitly omitted\"\n",
      "      +------------------------------------\n"
     ]
    }
   ],
   "source": [
    "llm = ChatAnthropic(model_name='claude-3-7-sonnet-latest', temperature=1)\n",
    "await tool_use_run(llm, 'look up Sinan Ozdemir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  + Exception Group Traceback (most recent call last):\n",
      "  |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3697, in run_code\n",
      "  |     await eval(code_obj, self.user_global_ns, self.user_ns)\n",
      "  |   File \"/var/folders/s6/2yjn7mrx2k1ch9m_rsw_dpj00000gn/T/ipykernel_33666/1754139658.py\", line 2, in <module>\n",
      "  |     await tool_use_run(llm, 'look up Sinan Ozdemir')\n",
      "  |   File \"/var/folders/s6/2yjn7mrx2k1ch9m_rsw_dpj00000gn/T/ipykernel_33666/1874888625.py\", line 7, in tool_use_run\n",
      "  |     async with stdio_client(server_params) as (read, write):\n",
      "  |   File \"/Users/sudhirpatil/miniconda3/lib/python3.11/contextlib.py\", line 222, in __aexit__\n",
      "  |     await self.gen.athrow(typ, value, traceback)\n",
      "  |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/mcp/client/stdio/__init__.py\", line 181, in stdio_client\n",
      "  |     async with (\n",
      "  |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 781, in __aexit__\n",
      "  |     raise BaseExceptionGroup(\n",
      "  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "  +-+---------------- 1 ----------------\n",
      "    | Exception Group Traceback (most recent call last):\n",
      "    |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/mcp/client/stdio/__init__.py\", line 188, in stdio_client\n",
      "    |     yield read_stream, write_stream\n",
      "    |   File \"/var/folders/s6/2yjn7mrx2k1ch9m_rsw_dpj00000gn/T/ipykernel_33666/1874888625.py\", line 8, in tool_use_run\n",
      "    |     async with ClientSession(read, write) as session:\n",
      "    |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 781, in __aexit__\n",
      "    |     raise BaseExceptionGroup(\n",
      "    | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "    +-+---------------- 1 ----------------\n",
      "      | Traceback (most recent call last):\n",
      "      |   File \"/var/folders/s6/2yjn7mrx2k1ch9m_rsw_dpj00000gn/T/ipykernel_33666/1874888625.py\", line 11, in tool_use_run\n",
      "      |     ai_message = llm.bind_tools(tools).invoke([HumanMessage(content=initial_message)])\n",
      "      |                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 5711, in invoke\n",
      "      |     return self.bound.invoke(\n",
      "      |            ^^^^^^^^^^^^^^^^^^\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 395, in invoke\n",
      "      |     self.generate_prompt(\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 1025, in generate_prompt\n",
      "      |     return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "      |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 842, in generate\n",
      "      |     self._generate_with_cache(\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 1091, in _generate_with_cache\n",
      "      |     result = self._generate(\n",
      "      |              ^^^^^^^^^^^^^^^\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 1184, in _generate\n",
      "      |     raise e\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/langchain_openai/chat_models/base.py\", line 1179, in _generate\n",
      "      |     raw_response = self.client.with_raw_response.create(**payload)\n",
      "      |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
      "      |     return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "      |                                       ^^^^^^^^^^^^^^^^^^^^^\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
      "      |     return func(*args, **kwargs)\n",
      "      |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1147, in create\n",
      "      |     return self._post(\n",
      "      |            ^^^^^^^^^^^\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n",
      "      |     return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "      |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "      |   File \"/Users/sudhirpatil/code/oreilly-ai-agents/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n",
      "      |     raise self._make_status_error_from_response(err.response) from None\n",
      "      | openai.BadRequestError: Error code: 400 - {'error': {'message': 'invalid model ID', 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "      +------------------------------------\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"openrouter/optimus-alpha\", temperature=1, base_url=\"https://openrouter.ai/api/v1\", api_key=os.environ[\"OPENROUTER_API_KEY\"])\n",
    "await tool_use_run(llm, 'look up Sinan Ozdemir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"google/gemini-2.0-flash-001\", temperature=1, base_url= \"https://openrouter.ai/api/v1\", api_key=os.environ[\"OPENROUTER_API_KEY\"])\n",
    "\n",
    "await tool_use_run(llm, 'Add a new row and just write \"To do\" in it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "errors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llms = [\n",
    "            ChatOpenAI(model=\"gpt-4o-mini\", temperature=1),\n",
    "            ChatOpenAI(model=\"gpt-4o\", temperature=1),\n",
    "        \n",
    "            ChatAnthropic(model_name='claude-3-5-haiku-latest', temperature=1),\n",
    "            ChatAnthropic(model_name='claude-3-7-sonnet-latest', temperature=1),\n",
    "        \n",
    "            ChatOpenAI(model=\"openrouter/optimus-alpha\", temperature=1, base_url= \"https://openrouter.ai/api/v1\", api_key=os.environ[\"OPENROUTER_API_KEY\"]),\n",
    "            \n",
    "            ChatOpenAI(model=\"google/gemini-2.0-flash-001\", temperature=1, base_url= \"https://openrouter.ai/api/v1\", api_key=os.environ[\"OPENROUTER_API_KEY\"]),\n",
    "            \n",
    "            ChatOpenAI(model=\"deepseek/deepseek-chat-v3-0324\", temperature=1, base_url= \"https://openrouter.ai/api/v1\", api_key=os.environ[\"OPENROUTER_API_KEY\"]),\n",
    "            \n",
    "            ChatOpenAI(model=\"meta-llama/llama-4-maverick\", temperature=1, base_url= \"https://openrouter.ai/api/v1\", api_key=os.environ[\"OPENROUTER_API_KEY\"]),\n",
    "            ChatOpenAI(model=\"meta-llama/llama-4-scout\", temperature=1, base_url= \"https://openrouter.ai/api/v1\", api_key=os.environ[\"OPENROUTER_API_KEY\"]),\n",
    "            ChatOpenAI(model=\"meta-llama/llama-3.3-70b-instruct\", temperature=1, base_url= \"https://openrouter.ai/api/v1\", api_key=os.environ[\"OPENROUTER_API_KEY\"]),\n",
    "            \n",
    "            ChatOpenAI(model=\"x-ai/grok-3-beta\", temperature=1, base_url= \"https://openrouter.ai/api/v1\", api_key=os.environ[\"OPENROUTER_API_KEY\"]),\n",
    "            ChatOpenAI(model=\"gpt-4.1\", temperature=1),\n",
    "            ChatOpenAI(model=\"gpt-4.1-mini\", temperature=1)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from random import sample\n",
    "import pandas as pd\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "n = 10\n",
    "import time\n",
    "\n",
    "for initial_message, expected_tool in tqdm(tool_selection_test_data):\n",
    "    for llm in llms:\n",
    "        for _ in range(n):\n",
    "            try:\n",
    "                response, tools_used, mcp_tool_order = await tool_use_run(llm, initial_message)\n",
    "                first_tool_used_by_agent = tools_used[0][0] if tools_used else None\n",
    "                time.sleep(0.3)\n",
    "            except Exception as e:\n",
    "                errors.append(f'error: {e} on llm: {llm}')\n",
    "            results.append(\n",
    "                {\n",
    "                    'llm': llm.model_name if hasattr(llm, 'model_name') else llm.model,\n",
    "                    'initial_message': initial_message,\n",
    "                    'first_tool_used_by_agent': first_tool_used_by_agent,\n",
    "                    'tools_used_by_agent': tools_used, \n",
    "                    'mcp_tool_order': mcp_tool_order, \n",
    "                    'expected_tool': expected_tool,\n",
    "                    'correct_tool_index': mcp_tool_order.index(expected_tool),\n",
    "                    'chosen_tool_index': mcp_tool_order.index(first_tool_used_by_agent) if first_tool_used_by_agent in mcp_tool_order else None\n",
    "                }\n",
    "            )\n",
    "            if len(results) % 10 == 0:\n",
    "                print(pd.DataFrame(results)['chosen_tool_index'].mean(), pd.DataFrame(results)['correct_tool_index'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)#.fillna(-1)\n",
    "print(results_df.shape)\n",
    "results_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['chosen_tool_index'].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['llm'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['tool_correct'] = (results_df['correct_tool_index'] == results_df['chosen_tool_index'])\n",
    "results_df.groupby('llm')['tool_correct'].mean().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set the style\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial']\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Calculate mean accuracy\n",
    "mean_accuracy = results_df.groupby('llm')['tool_correct'].mean().sort_values()\n",
    "\n",
    "# Custom colors with higher saturation\n",
    "colors = ['#3498db', '#2ecc71']  # Vibrant blue and green\n",
    "\n",
    "# Create bars\n",
    "bars = ax.bar(\n",
    "    mean_accuracy.index,\n",
    "    mean_accuracy.values,\n",
    "    color=colors,\n",
    "    width=0.6,\n",
    "    edgecolor='white',\n",
    "    linewidth=1.5\n",
    ")\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(\n",
    "        bar.get_x() + bar.get_width()/2.,\n",
    "        height,\n",
    "        f'{height:.2%}',\n",
    "        ha='center',\n",
    "        va='bottom',\n",
    "        fontsize=13,\n",
    "        fontweight='bold'\n",
    "    )\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_title('Tool Selection Accuracy by Language Model', \n",
    "             pad=20, \n",
    "             fontsize=15, \n",
    "             fontweight='bold')\n",
    "ax.set_xlabel('Language Model', fontsize=12, labelpad=10)\n",
    "ax.set_ylabel('Accuracy', fontsize=12, labelpad=10)\n",
    "\n",
    "# Customize grid\n",
    "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "ax.set_axisbelow(True)  # Place gridlines behind bars\n",
    "\n",
    "# Customize spines\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_linewidth(0.5)\n",
    "ax.spines['bottom'].set_linewidth(0.5)\n",
    "\n",
    "# Set y-axis limits with some padding\n",
    "ax.set_ylim(0, min(1.1, max(mean_accuracy.values) * 1.15))\n",
    "\n",
    "# Format y-axis as percentage\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "# Rotate x-axis labels\n",
    "ax.set_xticklabels(mean_accuracy.index, rotation=30, ha='right', fontsize=12)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.savefig('tool_acc.png', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_tool_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Group by LLM and tool\n",
    "grouped = results_df.groupby(['llm', 'expected_tool'])\n",
    "\n",
    "# Compute TP, FP, FN\n",
    "metrics = []\n",
    "metrics = []\n",
    "\n",
    "for llm in results_df['llm'].unique():\n",
    "    for tool in results_df['expected_tool'].unique():\n",
    "        df_llm = results_df[results_df['llm'] == llm]\n",
    "\n",
    "        tp = ((df_llm['first_tool_used_by_agent'] == tool) & (df_llm['expected_tool'] == tool)).sum()\n",
    "        fp = ((df_llm['first_tool_used_by_agent'] == tool) & (df_llm['expected_tool'] != tool)).sum()\n",
    "        fn = ((df_llm['first_tool_used_by_agent'] != tool) & (df_llm['expected_tool'] == tool)).sum()\n",
    "\n",
    "        precision = tp / (tp + fp) if (tp + fp) else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) else 0\n",
    "\n",
    "        metrics.append({\n",
    "            'llm': llm,\n",
    "            'tool': tool,\n",
    "            'precision': precision,\n",
    "            'recall': recall\n",
    "        })\n",
    "\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pivot_precision = metrics_df.pivot(index='llm', columns='tool', values='precision')\n",
    "pivot_recall = metrics_df.pivot(index='llm', columns='tool', values='recall')\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "sns.heatmap(pivot_precision, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
    "plt.title(\"Precision Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "sns.heatmap(pivot_recall, annot=True, fmt=\".2f\", cmap=\"Greens\")\n",
    "plt.title(\"Recall Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\n",
    "    (results_df['expected_tool'] == 'google_spreadsheet_tool') & \n",
    "    (results_df['llm'].str.contains('gemini'))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df[\n",
    "    (results_df['expected_tool'] == 'firecrawl_tool') & \n",
    "    (results_df['tool_correct'] == False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model_choices = {}\n",
    "\n",
    "# Define the model name\n",
    "for MODEL_NAME in results_df['llm'].unique():\n",
    "    \n",
    "    # Filter the results for the specified model\n",
    "    llm_results = results_df[results_df['llm'] == MODEL_NAME].dropna()\n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    # Define bar width and x-axis locations\n",
    "    bar_width = 0.4\n",
    "    x = np.arange(len(llm_results['correct_tool_index'].unique()) )\n",
    "    \n",
    "    # Aggregate the data for plotting\n",
    "    correct_counts = llm_results['correct_tool_index'].value_counts(normalize=True).sort_index()\n",
    "    chosen_counts = llm_results['chosen_tool_index'].value_counts(normalize=True).sort_index()\n",
    "    \n",
    "    # Align indices\n",
    "    correct_counts = correct_counts.reindex(x, fill_value=0)\n",
    "    chosen_counts = chosen_counts.reindex(x, fill_value=0)\n",
    "\n",
    "    model_choices[MODEL_NAME] = ((chosen_counts - correct_counts) / correct_counts)\n",
    "    \n",
    "    # Plot side-by-side bars with new colors\n",
    "    bars_correct = ax.bar(\n",
    "        x - bar_width / 2, correct_counts, width=bar_width, color='#2ecc71', edgecolor='white', linewidth=1.5, label='Correct Tool Index'\n",
    "    )\n",
    "    \n",
    "    bars_chosen = ax.bar(\n",
    "        x + bar_width / 2, chosen_counts, width=bar_width, color='#e67e22', edgecolor='white', linewidth=1.5, label='Chosen Tool Index'\n",
    "    )\n",
    "    \n",
    "    # Add value labels on top of each bar\n",
    "    for bars in [bars_correct, bars_chosen]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width() / 2.,\n",
    "                height,\n",
    "                f'{round(height * 100, 1)}%',\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                fontsize=12,\n",
    "                fontweight='bold'\n",
    "            )\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_title(f'Correct vs Chosen Tool Index for {MODEL_NAME}', fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('Tool Index', fontsize=12)\n",
    "    ax.set_ylabel('Frequency', fontsize=12)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(x, fontsize=12)\n",
    "    \n",
    "    # Customize grid and spines\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(0.5)\n",
    "    ax.spines['bottom'].set_linewidth(0.5)\n",
    "    \n",
    "    # Add legend\n",
    "    ax.legend(title='Index Type', fontsize=12)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pos_bias(proportion_data, title):  # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Define colors based on positive/negative values\n",
    "    colors = ['#2ecc71' if val >= 0 else '#e74c3c' for val in proportion_data]\n",
    "    \n",
    "    # Plot bar chart\n",
    "    bars = ax.bar(proportion_data.index, proportion_data.values, color=colors, edgecolor='white', linewidth=1.5)\n",
    "    \n",
    "    # Add value labels on top of each bar\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width() / 2.,\n",
    "            height,\n",
    "            f'{height:.2%}',\n",
    "            ha='center',\n",
    "            va='bottom' if height >= 0 else 'top',\n",
    "            fontsize=12,\n",
    "            fontweight='bold',\n",
    "            color='black'\n",
    "        )\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_title(title, fontsize=16, fontweight='bold')\n",
    "    ax.set_xlabel('Correct Tool Index', fontsize=12)\n",
    "    ax.set_ylabel('Average Proportion (Chosen - Correct / Correct)', fontsize=12)\n",
    "    \n",
    "    # Customize grid and spines\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_linewidth(0.5)\n",
    "    ax.spines['bottom'].set_linewidth(0.5)\n",
    "    \n",
    "    # Set y-axis limits for better visualization\n",
    "    ax.set_ylim(min(proportion_data.values) - 0.05, max(proportion_data.values) + 0.05)\n",
    "    \n",
    "    # Format y-axis as percentage\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    try:\n",
    "        plt.savefig(f'pos_bias_tool_{title}.png', dpi=1000)\n",
    "    except:\n",
    "        pass\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming model_choices is your list of Series\n",
    "proportion_data = pd.concat([v for k, v in model_choices.items()], axis=1).mean(axis=1)\n",
    "plot_pos_bias(proportion_data, 'Average Proportion between Chosen and Correct Tool Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assuming model_choices is your list of Series\n",
    "for model, _ in model_choices.items():\n",
    "    proportion_data = pd.concat([v for k, v in model_choices.items() if model in k], axis=1).mean(axis=1)\n",
    "    plot_pos_bias(proportion_data, f'{model} Proportion between Chosen and Correct Tool Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Combatting Positional Bias\n",
    "\n",
    "Sort tools in descending order of similiarty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"Loading the sentence-transformers model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "def sort_snippets_by_similarity(snippets, question):\n",
    "    \"\"\"\n",
    "    Sort tool snippets by their similarity to a given question using sentence transformers.\n",
    "    \n",
    "    Args:\n",
    "        snippets: List of text snippets to sort\n",
    "        question: The question to compare against\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries containing the original snippets and their similarity scores,\n",
    "        sorted in descending order of similarity\n",
    "    \"\"\"\n",
    "    # Load a pre-trained sentence transformer model\n",
    "    \n",
    "    # Generate embeddings for the question\n",
    "    question_embedding = model.encode([question])[0]\n",
    "    \n",
    "    # Generate embeddings for all snippets\n",
    "    snippet_embeddings = model.encode(snippets)\n",
    "    \n",
    "    # Calculate cosine similarities\n",
    "    similarities = []\n",
    "    for i, (snippet, embedding) in enumerate(zip(snippets, snippet_embeddings)):\n",
    "        # Calculate cosine similarity\n",
    "        similarity = cosine_similarity([embedding], [question_embedding])[0][0]\n",
    "        \n",
    "        # Get the tool name from the snippet\n",
    "        tool_name = snippet.split('def')[1].split('(')[0].strip() if 'def' in snippet else f\"Unknown Tool {i}\"\n",
    "        \n",
    "        similarities.append({\n",
    "            'index': i,\n",
    "            'tool_name': tool_name,\n",
    "            'snippet': snippet,\n",
    "            'similarity': similarity\n",
    "        })\n",
    "    \n",
    "    # Sort by similarity in descending order\n",
    "    similarities.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "    \n",
    "    return similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_similarity_based_mcp(question, mcp_path='similarity_based_mcp.py'):\n",
    "    \"\"\"\n",
    "    Generate an MCP server file with tools sorted by their relevance to the given question.\n",
    "    \n",
    "    Args:\n",
    "        question: The question to sort tools by\n",
    "        mcp_path: Path where the MCP server file will be saved\n",
    "        \n",
    "    Returns:\n",
    "        Tuple containing the absolute path of the generated file and the list of tool names in order\n",
    "    \"\"\"\n",
    "    # Sort snippets by similarity to the question\n",
    "    sorted_snippets = sort_snippets_by_similarity(tool_snippets, question)\n",
    "    \n",
    "    # Extract the sorted snippets\n",
    "    ordered_snippets = [item['snippet'] for item in sorted_snippets]\n",
    "    \n",
    "    # Create full server code\n",
    "    MCP_SERVER = f'''\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "mcp = FastMCP(\"MCP Example\")\n",
    "{''.join(ordered_snippets)}\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"stdio\")\n",
    "    '''\n",
    "    \n",
    "    # Save to file\n",
    "    with open(mcp_path, 'w') as f:\n",
    "        f.write(MCP_SERVER)\n",
    "    \n",
    "    # Extract tool names for return value\n",
    "    tool_names = [item['tool_name'] for item in sorted_snippets]\n",
    "    \n",
    "    return os.path.abspath(mcp_path), tool_names\n",
    "\n",
    "question = \"Go to loopgenius.com\"\n",
    "\n",
    "mcp_path, tool_names = generate_similarity_based_mcp(question)\n",
    "print(f\"\\nSaved to: {mcp_path}\")\n",
    "print(f\"Tool order: {tool_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_llms = [\n",
    "            ChatOpenAI(model=\"gpt-4o-mini\", temperature=1)\n",
    "        ]\n",
    "new_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to suppress a warning\n",
    "%env TOKENIZERS_PARALLELISM=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from random import sample\n",
    "import pandas as pd\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "n = 10\n",
    "import time\n",
    "\n",
    "for initial_message, expected_tool in tqdm(tool_selection_test_data):\n",
    "    for llm in updated_llms:\n",
    "        for _ in range(n):\n",
    "            try:\n",
    "                response, tools_used, mcp_tool_order = await tool_use_run(llm, initial_message)\n",
    "                first_tool_used_by_agent = tools_used[0][0] if tools_used else None\n",
    "                time.sleep(0.3)\n",
    "            except Exception as e:\n",
    "                errors.append(f'error: {e} on llm: {llm}')\n",
    "            new_results.append(\n",
    "                {\n",
    "                    'llm': llm.model_name if hasattr(llm, 'model_name') else llm.model,\n",
    "                    'initial_message': initial_message,\n",
    "                    'first_tool_used_by_agent': first_tool_used_by_agent,\n",
    "                    'tools_used_by_agent': tools_used, \n",
    "                    'mcp_tool_order': mcp_tool_order, \n",
    "                    'expected_tool': expected_tool,\n",
    "                    'correct_tool_index': mcp_tool_order.index(expected_tool),\n",
    "                    'chosen_tool_index': mcp_tool_order.index(first_tool_used_by_agent) if first_tool_used_by_agent in mcp_tool_order else None\n",
    "                }\n",
    "            )\n",
    "            if len(new_results) % 10 == 0:\n",
    "                print(pd.DataFrame(new_results)['chosen_tool_index'].mean(), pd.DataFrame(new_results)['correct_tool_index'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results_df = pd.DataFrame(new_results)\n",
    "new_results_df['tool_correct'] = new_results_df['correct_tool_index'] == new_results_df['chosen_tool_index']\n",
    "new_results_df.groupby('llm')['tool_correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(new_results)['chosen_tool_index'].mean() - pd.DataFrame(new_results)['correct_tool_index'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results_df[new_results_df['tool_correct'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
